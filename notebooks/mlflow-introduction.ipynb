{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d546b38-f8b7-438d-9808-abfa3c61c993",
   "metadata": {},
   "source": [
    "# Tutorial : introduction to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0f60f-e70f-41f4-99ed-1e9800cfa9f7",
   "metadata": {},
   "source": [
    "This first application introduces the basic concepts of `MLFlow`. The goal is to predict the income class of individuals using a sample data from the US Census and a Random Forest classifier using the popular [scikit-learn](https://scikit-learn.org/stable/) machine learning `Python` library. \n",
    "\n",
    "We first illustrate how we would perform the training and fine-tuning of the model in a traditional way. Then, we show how we can integrate it as an **MLflow experiment**, so as to **log** relevant parameters and metrics in `MLflow`'s **tracking server** and visualize them in the UI. Finally, we illustrate how selected models can transition from the tracking server to the **model registry**, and how they can then be used from there to perform inference on new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2ed5cf-810d-47ea-ade3-f92f5e3771be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/mamba/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba85244-30af-43f4-92f2-a15bf67cf16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b67a65-102f-4069-8cc8-4c64dcdc00ec",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed086e6",
   "metadata": {},
   "source": [
    "For this application, we'll use a classical dataset extracted from the 1994 US Census bureau data. The goal is to determine whether a person makes over $50K a year ('>50K') or less ('<=50K') using sociodemographic characteristics on the selected individuals. As the available variables are generally self-explanatory, we won't describe the data much, but more information on them can be found in the original [Kaggle challenge](https://www.kaggle.com/datasets/uciml/adult-census-income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24ae610-bb74-405b-9df0-06d423fd03c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/adult-census-us.csv\"\n",
    "df_census = pd.read_csv(DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322565d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0    2         State-gov   77516  Bachelors             13   \n",
       "1    3  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2    2           Private  215646    HS-grad              9   \n",
       "3    3           Private  234721       11th              7   \n",
       "4    1           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek native-country  class  \n",
       "0            1            0             2  United-States  <=50K  \n",
       "1            0            0             0  United-States  <=50K  \n",
       "2            0            0             2  United-States  <=50K  \n",
       "3            0            0             2  United-States  <=50K  \n",
       "4            0            0             2           Cuba  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291ee38",
   "metadata": {},
   "source": [
    "The goal is to predict the income class, so we must first set it aside from the training data. As this variable consists in string-encoded categories, we must encode it in a numerical format to be able to feed it to a machine learning model. A common practice for ordinal data (data for which an order exists, such as income class) is to encode labels as subsequent integers starting at 0, a technique known as **label encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30313ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X = df_census.drop(columns=\"class\")\n",
    "y = le.fit_transform(df_census[\"class\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770dee4",
   "metadata": {},
   "source": [
    "These new integer-encoded categories can naturally be mapped to the original values of the variable, and conversely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fe46f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The encoded classes\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c732d24c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "['<=50K' '<=50K' '<=50K' ... '<=50K' '<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "# The corresponding original classes\n",
    "print(y)\n",
    "print(np.array([le.classes_[i] for i in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f2f3e",
   "metadata": {},
   "source": [
    "A common practice in machine learning projects is to start by setting a fraction of the data aside as a **test dataset**. This data will be used at the very end of the project in order to properly evaluate the generalization performance of our selected algorithm, i.e. how it would perform on new unseen data. The rest of the data (**training dataset**) will be used to train the algorithms and compare their performance. Without this step, we are at risk of overfitting our models on the available data so that our evaluation metrics would no longer properly estimate the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fded59-b6f4-4647-809b-643bef3b056a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c259a228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39073 entries, 22729 to 2732\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             39073 non-null  int64 \n",
      " 1   workclass       36830 non-null  object\n",
      " 2   fnlwgt          39073 non-null  int64 \n",
      " 3   education       39073 non-null  object\n",
      " 4   education-num   39073 non-null  int64 \n",
      " 5   marital-status  39073 non-null  object\n",
      " 6   occupation      36821 non-null  object\n",
      " 7   relationship    39073 non-null  object\n",
      " 8   race            39073 non-null  object\n",
      " 9   sex             39073 non-null  object\n",
      " 10  capitalgain     39073 non-null  int64 \n",
      " 11  capitalloss     39073 non-null  int64 \n",
      " 12  hoursperweek    39073 non-null  int64 \n",
      " 13  native-country  38404 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab462d9",
   "metadata": {},
   "source": [
    "These general information show that thousands of observations are missing for some variables. To avoid wasting data and since these might not be missing-at-random, we'll impute values for the missing ones :\n",
    "- for numerical variables, we'll impute the median of the variable\n",
    "- for categorical variables, we'll impute the mode, i.e. the most frequent category in the data\n",
    "\n",
    "As previously, string-encoded categorical variables must also be converted to some form of numerical data. We'll use the same encoding strategy as the one used to encode the target variable.\n",
    "\n",
    "So as to make all these steps as reproducible as possible, we formalize them as a `scikit-learn` `Pipeline` object. More information on their justification and the way there are used can be found in the [documentation](https://scikit-learn.org/stable/modules/compose.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0135c24-826e-47e3-931c-7db4ec20b9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "mode_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "categorical_transformer = make_pipeline(mode_imputer, ordinal_encoder)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical\", median_imputer, make_column_selector(dtype_include=np.int64)),\n",
    "        (\"categorical\", categorical_transformer, make_column_selector(dtype_include=object))\n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab4ca8",
   "metadata": {},
   "source": [
    "As most `scikit-learn` objects, the pipeline must first `fit` the data (e.g. compute the most frequent value or median). Then, we can use it to `transform` the data. The resulting object is a `NumPy` array with the same structure as the original data. It is not very useful per se, but it shows us that the categorical variables are indeed transformed into numerical values. This numerical array can then be fed to a machine learning model to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58964862-1e9f-4fca-b158-4891057db7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.17372e+05, 7.00000e+00, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [2.00000e+00, 3.57720e+05, 1.10000e+01, ..., 4.00000e+00,\n",
       "        0.00000e+00, 3.80000e+01],\n",
       "       [4.00000e+00, 2.02242e+05, 9.00000e+00, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       ...,\n",
       "       [2.00000e+00, 3.44624e+05, 1.00000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [3.00000e+00, 1.04489e+05, 1.30000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [0.00000e+00, 1.86925e+05, 1.00000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb81610-0b95-4dcd-96b0-ec2eebbc7281",
   "metadata": {},
   "source": [
    "## Tracking machine learning experiments : the classical way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fd5be",
   "metadata": {},
   "source": [
    "In order to really understand why the MLOps approach is desirable, we must first get an idea of how we would train our model without it, i.e. the \"classical\" way. The workflow we are trying to achieve is best described by the following figure from the [scikit-learn documentation](https://scikit-learn.org/stable/).\n",
    "\n",
    "<img src=\"img/grid_search_workflow.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Using the training data, we want to train a model so as to get the best generalization performance, i.e. minimize the prediction error on unseen data. To do so, we have to **fine-tune** the **hyperparameters** of our model, i.e. find the combination of **hyperparameters** that provide the best performance. In order to avoid **overfitting** when doing so, we use a procedure called **cross-validation** (described in details [here](https://scikit-learn.org/stable/modules/cross_validation.html)). When we have found the optimal set of hyperparameters, we use the model trained with those for a final evaluation on the test set.\n",
    "\n",
    "In this example, we train a *Random Forest* to discriminate the two income classes. First, we build a `Pipeline` object that integrates the preprocessing step as well as the model, so as to be able to improve reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef674c48-5111-40af-81d4-02c0ec18ad22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classifier', rf_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f87d5",
   "metadata": {},
   "source": [
    "Although the hyperparameters provided natively by `scikit-learn` are usually good defaults, we will of course want to check whether we can improve the performance further by **fine-tuning** the relevant hyperparameters. To do so, we use the *grid search* method, which amounts to testing all the possible hyperparameters combinations along given values (*grid*) for these hyperparameters. For each combination, a performance evaluation is performed using a 5-folds *cross-validation*. As the accuracy is rarely a relevant metric for classification problems because of class imbalance, we also request the precision, the recall and the f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "819fa1df-292f-4c3d-b9af-c2e164f391a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [50, 100, 200],\n",
    "    \"classifier__max_leaf_nodes\": [5, 10, 50]\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipe_rf, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    "                         refit=\"f1\",\n",
    "                         cv=5, \n",
    "                         n_jobs=5, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c3f16",
   "metadata": {},
   "source": [
    "**Question** : can you guess the total number of `fit` steps that will be performed when calling the `fit` method on the `pipe_gscv` object ?\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "    <font size=\\\"3\\\" color=\\\"darkgreen\\\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "From the grid search only, there are 3 * 3 = 9 candidate models to train. However, for each combination, a 5-folds cross-validation is performed, which involves 5 training steps (*fits*). So altogether, there will be 9 * 5 = 45 *fits* to compute.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd56281e-31dc-4a24-940e-6eb180aad8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                         SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b12d0&gt;),\n",
       "                                                                        (&#x27;categorical&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;ordinalencoder&#x27;,\n",
       "                                                                                          OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b27a0&gt;)])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={&#x27;classifier__max_leaf_nodes&#x27;: [5, 10, 50],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                         SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b12d0&gt;),\n",
       "                                                                        (&#x27;categorical&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;ordinalencoder&#x27;,\n",
       "                                                                                          OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b27a0&gt;)])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={&#x27;classifier__max_leaf_nodes&#x27;: [5, 10, 50],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;],\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;numerical&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b12d0&gt;),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;ordinalencoder&#x27;,\n",
       "                                                                   OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b27a0&gt;)])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numerical&#x27;, SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b12d0&gt;),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;ordinalencoder&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b27a0&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b12d0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b27a0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('numerical',\n",
       "                                                                         SimpleImputer(strategy='median'),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b12d0>),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('ordinalencoder',\n",
       "                                                                                          OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f8d630b27a0>)])),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'classifier__max_leaf_nodes': [5, 10, 50],\n",
       "                         'classifier__n_estimators': [50, 100, 200]},\n",
       "             refit='f1', scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217e9ab",
   "metadata": {},
   "source": [
    "We can get detailed results for each candidate model in a `Pandas DataFrame`. This enables us to compare the models and select the best candidate based on their respective performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4541f8d2-7fac-4407-928d-b70c3640fa8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__max_leaf_nodes</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.372760</td>\n",
       "      <td>0.084143</td>\n",
       "      <td>0.113134</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.827639</td>\n",
       "      <td>0.833781</td>\n",
       "      <td>0.832118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>7</td>\n",
       "      <td>0.541993</td>\n",
       "      <td>0.545963</td>\n",
       "      <td>0.543811</td>\n",
       "      <td>0.557421</td>\n",
       "      <td>0.528157</td>\n",
       "      <td>0.543469</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.455710</td>\n",
       "      <td>0.180711</td>\n",
       "      <td>0.159425</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.825080</td>\n",
       "      <td>0.831734</td>\n",
       "      <td>0.827895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>8</td>\n",
       "      <td>0.514732</td>\n",
       "      <td>0.536809</td>\n",
       "      <td>0.523557</td>\n",
       "      <td>0.530239</td>\n",
       "      <td>0.517448</td>\n",
       "      <td>0.524557</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.766344</td>\n",
       "      <td>0.360433</td>\n",
       "      <td>0.233709</td>\n",
       "      <td>0.027991</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.828279</td>\n",
       "      <td>0.825848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>9</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.514449</td>\n",
       "      <td>0.513224</td>\n",
       "      <td>0.512221</td>\n",
       "      <td>0.512735</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.642686</td>\n",
       "      <td>0.094695</td>\n",
       "      <td>0.114007</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 10, 'classifier...</td>\n",
       "      <td>0.831862</td>\n",
       "      <td>0.841331</td>\n",
       "      <td>0.837876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>4</td>\n",
       "      <td>0.567763</td>\n",
       "      <td>0.595828</td>\n",
       "      <td>0.590894</td>\n",
       "      <td>0.574122</td>\n",
       "      <td>0.583145</td>\n",
       "      <td>0.582351</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.904217</td>\n",
       "      <td>0.272134</td>\n",
       "      <td>0.178663</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 10, 'classifier...</td>\n",
       "      <td>0.831094</td>\n",
       "      <td>0.840691</td>\n",
       "      <td>0.837236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564931</td>\n",
       "      <td>0.591401</td>\n",
       "      <td>0.587281</td>\n",
       "      <td>0.575057</td>\n",
       "      <td>0.577098</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.372760      0.084143         0.113134        0.003589   \n",
       "1       2.455710      0.180711         0.159425        0.021745   \n",
       "2       4.766344      0.360433         0.233709        0.027991   \n",
       "3       1.642686      0.094695         0.114007        0.012026   \n",
       "4       2.904217      0.272134         0.178663        0.037922   \n",
       "\n",
       "  param_classifier__max_leaf_nodes param_classifier__n_estimators  \\\n",
       "0                                5                             50   \n",
       "1                                5                            100   \n",
       "2                                5                            200   \n",
       "3                               10                             50   \n",
       "4                               10                            100   \n",
       "\n",
       "                                              params  split0_test_accuracy  \\\n",
       "0  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.827639   \n",
       "1  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.825080   \n",
       "2  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.823800   \n",
       "3  {'classifier__max_leaf_nodes': 10, 'classifier...              0.831862   \n",
       "4  {'classifier__max_leaf_nodes': 10, 'classifier...              0.831094   \n",
       "\n",
       "   split1_test_accuracy  split2_test_accuracy  ...  std_test_recall  \\\n",
       "0              0.833781              0.832118  ...         0.013073   \n",
       "1              0.831734              0.827895  ...         0.007155   \n",
       "2              0.828279              0.825848  ...         0.005810   \n",
       "3              0.841331              0.837876  ...         0.010626   \n",
       "4              0.840691              0.837236  ...         0.009021   \n",
       "\n",
       "   rank_test_recall  split0_test_f1  split1_test_f1  split2_test_f1  \\\n",
       "0                 7        0.541993        0.545963        0.543811   \n",
       "1                 8        0.514732        0.536809        0.523557   \n",
       "2                 9        0.503067        0.520714        0.514449   \n",
       "3                 4        0.567763        0.595828        0.590894   \n",
       "4                 5        0.564931        0.591401        0.587281   \n",
       "\n",
       "   split3_test_f1  split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0        0.557421        0.528157      0.543469     0.009356             7  \n",
       "1        0.530239        0.517448      0.524557     0.008130             8  \n",
       "2        0.513224        0.512221      0.512735     0.005667             9  \n",
       "3        0.574122        0.583145      0.582351     0.010351             4  \n",
       "4        0.575057        0.577098      0.579154     0.009374             5  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_results = pd.DataFrame(pipe_gscv.cv_results_)\n",
    "gscv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75b873",
   "metadata": {},
   "source": [
    "The fitted `Pipeline` object actually keep tracks of the best model for us. We can thus show the best performing set of hyperparameters, and use the model trained with these hyperparameters to compute the final score on the test set (not used until yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23990354-0989-454f-a1d3-c2f230d82d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_leaf_nodes': 50, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(pipe_gscv.best_params_)\n",
    "\n",
    "best_model = pipe_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1042c22b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-score on test data : 0.646433990895296\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final F1-score on test data : {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e06080",
   "metadata": {},
   "source": [
    "In order for this analysis to be reproducible, we must find a way to export the results. Fortunately, `scikit-learn` models are serializable. One way to persist them is to use `joblib` (see the [documentation on model persistence](https://scikit-learn.org/stable/model_persistence.html) for a more detailed discussion on possible way to export models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ca46c05-9f19-4269-9311-ccb547d40ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/pipeline_train_model_20230118.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"models/\"):\n",
    "    os.makedirs(\"models/\")\n",
    "joblib.dump(pipe_gscv, 'models/pipeline_train_model_20230118.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f985c76",
   "metadata": {},
   "source": [
    "This is convenient for the development phase, but it is also very clear that **this way of persisting models is not production-grade nor scalable** :\n",
    "- first and foremost, we lack a proper way to **track experiments** (data used for training, environment configuration, metrics...)\n",
    "- we can not easily visualize the various metrics so as to compare and select the best model\n",
    "- we can parallelize the cross-validation computation, but we can't readily parallelize the evaluation of each hyperparameters combination\n",
    "- there is no easy and standardized way to distribute the serialized models, so the collaboration of several team members on a given experiment is complicated\n",
    "\n",
    "The MLOps principles were precisely devised to solve these various problems. Let's see now how MLflow enables us to implement them easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc5b57-6dcc-4bf1-a2c3-29ae13300e46",
   "metadata": {},
   "source": [
    "## Tracking machine learning experiments : the MLFlow way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b194e-cbdf-463a-a7fd-e71ce0ddae19",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c359c4",
   "metadata": {},
   "source": [
    "The main component of `MLflow` is the *Tracking Server*, which tracks experiments and save the relevant data and metadata. More precisely, for each *run* (\"execution of some piece of data science code\"), the *Tracking Server* records : \n",
    "- **experiments data** (parameters, metrics, tags, notes, metadata, ...) in a **backend store** (in our case, a `PostgreSQL` database)\n",
    "- **artifacts** (models, files, images, ...) in an **artifact store** (in our case, `S3`-like storage)\n",
    "\n",
    "As a user, we communicate with the *Tracking Server* through a client (in our case, a `Jupyter` notebook with a `Python` kernel).\n",
    "\n",
    "Fortunately, in a properly set up environment, these three communication levels can be pre-configured so that they are relatively transparent to the user. This enables the data scientist to focus on the business task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c0dc8f",
   "metadata": {},
   "source": [
    "<img src=\"img/mlflow-tracking.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a155b49",
   "metadata": {},
   "source": [
    "The client must know the URI of the *tracking server*. If a `MLflow` instance has been launched on the SSP Cloud previous to the client, the client will automatically discover the URI. If not, it must be set manually. Opening this URL opens the UI of `MLflow`, which we will be using later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91a2e959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://user-jguay-754955.user.lab.sspcloud.fr\n"
     ]
    }
   ],
   "source": [
    "# Automatic discovery : if MLFlow has been launched before Jupyter/VSCode\n",
    "if \"MLFLOW_TRACKING_URI\" in os.environ:\n",
    "    print(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "else:\n",
    "    print(\"MLflow was not automatically discovered, a tracking URI must be provided manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15061562-8b91-45c4-8ada-f8458873e513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manual configuration : if MLFlow has been launched after Jupyter/VSCode\n",
    "# os.environ[\"MLFLOW_TRACKING_URI\"] = \"copy_uri_from_mlflow_service_README_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b55dd7-1f2c-42fa-941d-bad8412cdd16",
   "metadata": {},
   "source": [
    "### Tracking experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa949cb-bf32-4ce7-9bfe-7b7dc3ec00df",
   "metadata": {},
   "source": [
    "In the previous steps, we fine-tuned our model, i.e. we trained the same model with several different combinations of hyper-parameters in order to ultimately select the one with the best performance according to a given metric. In comparison with the \"traditional way\" we saw above, `MLflow` enables us to track these experiments in a much more refined way, compatible with the *MLOps* principles.\n",
    "\n",
    "The function `log_gsvc_to_mlflow` below enables us to convert the data contained in our `GridSearchCV` object (hyperparameters, metrics, artifact..) into an `MLflow` experiment, which can then be queried using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abd9585f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_gsvc_to_mlflow(gscv, mlflow_experiment_name):\n",
    "    \"\"\"Log a scikit-learn trained GridSearchCV object as an MLflow experiment.\"\"\"\n",
    "     # Set up MLFlow context\n",
    "    mlflow.set_experiment(experiment_name=mlflow_experiment_name)\n",
    "\n",
    "    for run_idx in range(len(gscv.cv_results_[\"params\"])):\n",
    "        # For each hyperparameter combination we trained the model with, we log a run in MLflow\n",
    "        run_name = f\"run {run_idx}\"\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            # Log hyperparameters\n",
    "            params = gscv.cv_results_[\"params\"][run_idx]\n",
    "            for param in params:\n",
    "                mlflow.log_param(param, params[param])\n",
    "\n",
    "            # Log fit metrics\n",
    "            scores = [score for score in gscv.cv_results_ if \"mean_test\" in score or \"std_test\" in score]\n",
    "            for score in scores:\n",
    "                mlflow.log_metric(score, gscv.cv_results_[score][run_idx])\n",
    "\n",
    "            # Log model as an artifact\n",
    "            mlflow.sklearn.log_model(gscv, \"gscv_model\")\n",
    "\n",
    "            # Log training data URL\n",
    "            mlflow.log_param(\"data_url\", DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a5f397a-1d6d-47de-94ca-29a2957c3427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/22 14:10:19 INFO mlflow.tracking.fluent: Experiment with name 'tutorial-mlflow-intro' does not exist. Creating a new experiment.\n",
      "/opt/mamba/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/mamba/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "log_gsvc_to_mlflow(gscv=pipe_gscv, mlflow_experiment_name=\"tutorial-mlflow-intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7228d7-d1ca-4188-9a7d-c3effff3e693",
   "metadata": {},
   "source": [
    "### Application 1.1: Tracking models with MLflow\n",
    "\n",
    "If the previous cell executed correctly, that means the experiments and in particular all the data we wanted `MLflow` to log are now available in the *tracking server*. In order to interact with these data and try to select the best model, we'll learn to use the UI. Please follow the following steps :\n",
    "1. Open the UI using the URI we printed above\n",
    "2. In the *Experiments* tab, open the \"tutorial-mlflow-intro\" experiment\n",
    "3. Verify that there are indeed 9 runs that have been recorded, one for each hyperparameters combination\n",
    "4. Open a given run and verify that you can retrieve the various information we wanted to log (hyperparameters, evaluation metrics, training data URL), check that you can download the serialized `scikit-learn` model, and check the `requirements.txt` file to understand how `MLflow` automatically inferred the required `Python` environment\n",
    "5. Go back to the list of runs by clicking again on the \"tutorial-mlflow-intro\" experiment\n",
    "6. Add additional columns using the *Columns* drop-down menu in the *Table* panel\n",
    "7. Sort the models in descending order according to the **mean test F1-score** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48f501-3446-49af-b75b-b53dbd84fc3b",
   "metadata": {},
   "source": [
    "### Application 1.2: Registering a model with MLflow\n",
    "In the previous section, we logged properly our experiment in the `MLflow` tracking server, which enables to compare our models and see the best performing ones in a visual way. Now, we want to be able to select a model, put it in production, and allow the other members of the projet to query it. For this to be possible, we have to **move the model from the tracking server to the model registry**.\n",
    "1. Consider both the high mean test F1-score and low standard deviation of test F1-score to make a decision on the best model.\n",
    "2. Click on the run corresponding to your chosen best model.\n",
    "3. Click on \"Register Model\"\n",
    "4. Create a New Model and give it a relevant name (e.g. \"rf-census\")\n",
    "5. Move to the model registry by clicking on the \"Models\" tab\n",
    "6. If everything worked correctly, you should see your model in the list of the registered models. Click on it to get the list of the registered versions of the model. For now, there is only one version as we pushed it only one time.\n",
    "7. Click on \"Version 1\" to get the information on this specific version of the model. Two things are especially interesting to note :\n",
    "\n",
    "   **a.** The \"Stage\" section. Here you can indicate to all members of the project what is stage of this specific model. Let's transition it to \"Production\" to indicate that is our reference model, which we want to deploy\n",
    "\n",
    "   **b.** The \"Source run\" section. Here you can retrieve the run that corresponds to this model. If you click on the run id, you retrieve all the information we logged (environment, metrics, artifacts location...). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de39735-cd52-46bb-9559-81c6f393b3c5",
   "metadata": {},
   "source": [
    "### Querying a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d910ff9-4b0c-46f0-8d5f-47c5a6b49a79",
   "metadata": {},
   "source": [
    "As above, let's perform the final evaluation on the test set using the model we put in production. We can retrieve the model either by its version or by its stage, should it have one. We fetch the model using the `mlflow.pyfunc.load_model` function. We then have our `scikit-learn` model, which can directly be used for prediction. Let's check that we find the same final F1-score on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4d454-6e9d-4a18-a144-ec534a647dc6",
   "metadata": {},
   "source": [
    "#### Using the version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b7520d8-8e7c-418e-acb6-5daac6ecc2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14658ee014e4d29a2e4db89c115a458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch the model\n",
    "model_name = \"rf-census\"\n",
    "version = 1\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ecfcbe7-2a23-47ea-8b75-d910fbae51ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-score on test data : 0.646433990895296\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final F1-score on test data : {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7391615-3290-47b8-a3b2-f7c9662774f9",
   "metadata": {},
   "source": [
    "This score indeed corresponds to the one we found in the \"classical ML training\" section using the best trained model !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1adeb-04ae-43c7-90a1-e09212e8063b",
   "metadata": {},
   "source": [
    "#### Using the stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb635aa-2a6f-4acb-b411-c8d71af2878d",
   "metadata": {},
   "source": [
    "Equivalently, we can use the stage of the model, which should produce the same score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a266fc1a-b560-4125-a9c8-0dee5c71ae98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5736e90cb4e049f1a3c91de01f4ab21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch the model\n",
    "model_name = \"rf-census\"\n",
    "stage = 'Production'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7615eb88-187a-4af8-8d5f-86a907462f63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-score on test data : 0.646433990895296\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final F1-score on test data : {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0c365-d352-4748-a5dc-44cb144d490a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e1325-5566-4816-95ac-d0c6c69791cf",
   "metadata": {},
   "source": [
    "`MLflow` enables us to **set our machine learning experiments to the standards of the `MLOps` approach** in a very user-friendly way :\n",
    "- data scientists can very easily decide what data they want to log for each experiment so as to **keep a detailed track of those experiments**\n",
    "- other members of the team (e.g. data engineers that might be in charge of deploying the model) can very easily fetch the model and use it for prediction in an application. To do so, they only need to know the name of the model as well as its version or its stage, but not the actual location of the artifact on the storage, as this layer is abstracted by `MLflow`. **This makes collaboration on machine learning projects very convenient and efficient**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aaa7d9-4ae6-42da-8de7-de6026b73e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa046f995eb80ac40c0869a1f9df46519f4ada8b8c395ef25dd1aa1a1a2fc63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
